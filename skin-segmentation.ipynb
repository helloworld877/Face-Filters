{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_elliptical_boundary_model(features):\n",
    "    # Fit a Gaussian Mixture Model (GMM) to the features\n",
    "    gmm = GaussianMixture(n_components=1, covariance_type='full')\n",
    "    gmm.fit(features) \n",
    "    # Get the parameters of the fitted Gaussian component\n",
    "    mean = gmm.means_[0]\n",
    "    print(gmm.means_)\n",
    "    cov_matrix = gmm.covariances_[0]\n",
    "\n",
    "    # Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[indices]\n",
    "    eigenvectors = eigenvectors[:, indices]\n",
    "\n",
    "    # Calculate the angle of rotation for the ellipse\n",
    "    angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))\n",
    "\n",
    "    # Create an ellipse using matplotlib\n",
    "    ellipse = Ellipse(mean, 2 * np.sqrt(5.991 * eigenvalues[0]),\n",
    "                      2 * np.sqrt(5.991 * eigenvalues[1]), angle=angle,\n",
    "                      fill=False, color='red', linewidth=2)\n",
    "\n",
    "    return ellipse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_elliptical_boundary_model(image, ellipse):\n",
    "    # Display the image with the fitted ellipse\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.gca().add_patch(ellipse)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132.59861328 123.13392904]]\n",
      "[[132.05597331 124.18502604]]\n",
      "[[132.01810872 124.16430013]]\n",
      "[[132.10290039 123.97375651]]\n",
      "[[132.11009115 123.96768555]]\n",
      "[[132.01414063 123.93054362]]\n",
      "[[132.33209635 123.53717773]]\n",
      "[[132.25957682 123.50180664]]\n",
      "[[132.16727865 123.38716797]]\n",
      "[[132.21319336 123.59216146]]\n",
      "[[132.26062826 123.41244792]]\n",
      "[[131.98709635 123.54932617]]\n",
      "[[132.11166667 123.44059245]]\n",
      "[[132.07909505 123.46219076]]\n",
      "[[132.11976888 123.45639974]]\n",
      "[[132.09439128 123.42622721]]\n",
      "[[132.09539062 123.48698242]]\n",
      "[[132.18539388 123.38213542]]\n",
      "[[132.25073568 123.35658203]]\n",
      "[[132.34635091 123.18013021]]\n",
      "[[132.47614583 123.14063151]]\n",
      "[[132.32138997 123.19088542]]\n",
      "[[132.35214844 123.27225911]]\n",
      "[[132.33509766 123.33300781]]\n",
      "[[132.3384082  123.31283203]]\n",
      "[[132.29684245 123.33046875]]\n",
      "[[132.40196289 123.23504232]]\n",
      "[[132.35927409 123.24586589]]\n",
      "[[132.36750326 123.27525065]]\n",
      "[[132.37877279 123.28541341]]\n",
      "[[132.33999349 123.25887695]]\n",
      "[[132.32332682 123.27005208]]\n",
      "[[132.21886393 123.51962891]]\n",
      "[[132.24205404 123.5312207 ]]\n",
      "[[132.19324219 123.45947591]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load an example image\n",
    "# image_path = \"face.jpeg\"\n",
    "# image = cv2.imread(image_path)\n",
    "camera = cv2.VideoCapture(0)\n",
    "cascade_path = \"./data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "clf = cv2.CascadeClassifier(str(cascade_path))\n",
    "\n",
    "while True:\n",
    "    # Get Frames from camera\n",
    "    _,image = camera.read()\n",
    "    # Convert the image to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Extract the Cr and Cb channels as features\n",
    "    features = ycrcb[:, :, 1:3].reshape((-1, 2))\n",
    "\n",
    "    # Fit an elliptical boundary model to the features\n",
    "    ellipse = fit_elliptical_boundary_model(features)\n",
    "    # ycbcr = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # # Define a color range for skin tones in YCbCr space\n",
    "    # lower_skin = np.array([0, 133, 77], dtype=\"uint8\")\n",
    "    # upper_skin = np.array([255, 173, 127], dtype=\"uint8\")\n",
    "\n",
    "    # # Create a binary mask for skin pixels\n",
    "    # skin_mask = cv2.inRange(ycbcr, lower_skin, upper_skin)\n",
    "\n",
    "    # # Apply the mask to the original image\n",
    "    # segmented_image = cv2.bitwise_and(image, image, mask=skin_mask)\n",
    "\n",
    "    # Visualize the elliptical boundary model\n",
    "    # visualize_elliptical_boundary_model(image, ellipse)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = clf.detectMultiScale(\n",
    "        gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # rendering the faces\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "        image[y:y+height, x:x+width, 0] = gray[y:y+height, x:x+width]\n",
    "        image[y:y+height, x:x+width, 1] = gray[y:y+height, x:x+width]\n",
    "        image[y:y+height, x:x+width, 2] = gray[y:y+height, x:x+width]\n",
    "\n",
    "    cv2.imshow(\"faces\", image)\n",
    "\n",
    "    if (cv2.waitKey(1) == ord(\"q\")):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_path = \"./data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "print(cascade_path)\n",
    "\n",
    "# make classifier\n",
    "\n",
    "clf = cv2.CascadeClassifier(str(cascade_path))\n",
    "\n",
    "# defining camera footage\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# render loop\n",
    "\n",
    "while True:\n",
    "    # reading form camera and detecting faces\n",
    "    _, frame = camera.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = clf.detectMultiScale(\n",
    "        gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # rendering the faces\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "        frame[y:y+height, x:x+width, 0] = gray[y:y+height, x:x+width]\n",
    "        frame[y:y+height, x:x+width, 1] = gray[y:y+height, x:x+width]\n",
    "        frame[y:y+height, x:x+width, 2] = gray[y:y+height, x:x+width]\n",
    "\n",
    "    cv2.imshow(\"faces\", frame)\n",
    "\n",
    "    if (cv2.waitKey(1) == ord(\"q\")):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
